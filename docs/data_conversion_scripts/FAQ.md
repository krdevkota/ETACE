Notes on usage of the data conversion python scripts
====

Data storage format: HDF5
====

The input data is stored in a ``HDF5`` container file (*.h5, .hdf5*) in a hierarchial form.

Currently, the ``HDF5`` file is arranged as follows:

- Each agent-type is contained in a separate HDF5 file, with the same name.

- Each HDF5 file has a single hierarchy, with the ``agent-type`` as the root, and the ``set`` and ``runs`` as the branches.

- the set and run branches each contain a DataFrame object, which contains a hierarchical index with these entries: ``iter``, ``id``.

- the DataFrame is written to the HDF5 file with the help of ``Pytable`` module of python.


A HDF5 file as described above can be created from the SQLite db files by using the data processing scripts, included in the data processing directory

*Note:* The ``SQLite`` db files follow this naming convention: ``set_*_run_*_iters.db``


Data conversion Scripts
====

All scripts run on Python 3.4.3 and above.

**XML_DB**

These scripts convert ``XML`` files to ``SQLite`` database files.

The script ``gendb.py`` creates SQLite db file from corresponding XML files in *many-to-one* fashion. So, for all xml files present in one input folder, one equivalent DB file is created in the output folder.
Example usage::

    python3 gendb.py -m path_to_model_xml -x path_xml_files [-o output_path]

Full usage example::

    python3 gendb.py -m /home/user/my_model/model.xml -x /home/user/my_xml_data/ -o /home/user/my_db_data/

The script ``gendb_special.py`` creates SQLite db file from corresponding XML files in *many-to-one* fashion, and skips missing Agents.
Example usage::

    python3 gendb_special.py -m path_to_model_xml -x path_xml_files [-o output_path]

Full usage example::

    python3 gendb_special.py -m /home/user/my_model/model.xml -x /home/user/my_xml_data/ -o /home/user/my_db_data/

Any help regarding the execution of the script can be obtained by using the following command in any terminal window::

    python gendb.py -h
    python gendb_special.py -h


**DB_HDF5**

- These scripts convert ``SQLite`` database files to ``HDF5`` files.
- There are two versions of the script currently, each having a slightly different functionality:

#. The script ``db_hdf5_v1.py`` creates HDF5 files from corresponding SQLite db files in *many-to-one* fashion.
   This means that for all db files present in some input folder, one corresponding big HDF5 file is created in the output folder.
   For input folders containing more hierarchies, the **-r** flag can be passed which results in one HDF5 file for the contents of each subfolder.

#. The script ``db_hdf5_v2.py`` creates HDF5 files from corresponding SQLite db files in *one-to-one* fashion.
   This means that for each db file present in the input folder, a corresponding HDF5 file is created in the output folder.
   To combine db files into a single HDF5 file, version 1 of the script named ``db_hdf5_v1.py`` should be used.

#. For the visualization library, we recommend to use the following workflow:

  ``db files: set_*_run_*_iters.db`` -> ``db_hdf5_v2.py`` -> ``merge_hdf_agentwise.py`` -> ``visualisation_scripts/main.py``

  - To convert db files to h5 files, the script ``db_hdf5_v2.py`` should be used.
  - To produce one h5 file per agent type, use the script ``merge_hdf_agentwise.py``
  - The FLAViz visualization scripts read from the files ``Agent_name.h5``

- Any help regarding the execution of the script can be obtained by using the following command in any terminal window::

    python db_hdf5_v1.py -h

- There is an option to specify a desired output folder for the output files, by passing an **-o** flag.
- However, by default the output is created either in the folder containing the script, in the same folder that has the input folder, or the input folder itself.
  These three options can be adjusted by commenting out the appropriate line in the script. Please look for the section *"Set output parameters"* in the script and comment out   the option that is not preferred. Currently, the default is such that the output is created in the input folder.
- There is an option to switch on/off the internal compression in the HDFStore, by using the **-z 1** flag.
- In addition, the chunk size can be specified by the option **-c 1000**.

**Notes:** 
        *There is no difference in the size of combined HDF5 (many-to-one generated by db_hdf5_v1.py) and separate HDF5 (one-to-one generated by db_hdf5_v2.py) files, even when compressing.*
        *However, separate HDF5 files are easier to manipulate when restructuring the HDF5 into files per Agent-type (i.e. Bank.h5, Eurostat.h5 and so on).*
        *Therefore, use of db_hdf5_v2.py is recommended for simplicity.*


**XML_HDF5**

- This script converts ``XML`` files to ``HDF5`` files directly (without first converting XML to db and then to h5).

- This script creates HDF5 files from corresponding XML files in *many-to-one* fashion. So, for all xml files present in one input folder, one equivalent HDF5 file is created in the output folder.
  
- For input folders containing a folder hierarchy, given that a *-r* flag is passed, one HDF5 file is created for the contents of each subfolder.

- Any help regarding the execution of the script can be obtained by using the following command in any terminal window::

        python xml_hdf5.py -h

- There is an option to specify a desired output folder for the output files, by passing an **-o** flag.
- However, by default the output is created either in the folder containing the script, in the same folder that has the input folder, or the input folder itself.
  These three options can be adjusted by commenting out the appropriate line in the script. Please look for the section *"Set output parameters"* in the script and comment out
  the option that is not preferred. Currently, the default is such that the output is created in the input folder.


**DB_XML**

- This script converts ``SQLite`` Db files to ``XML`` files.
- This script creates XML files from corresponding DB files in *one-to-many* fashion. For each DB file, a folder is created and multiple corresponding XML files are created inside the folder, based on time samples.
- The script runs on Python 3.4 and above. Any help regarding the execution of the script can be obtained by using the following command in any terminal window::

        python genxml.py -h

- There is an option to specify a desired output folder for the output files, by passing an **-o** flag.
- However, by default the output is created either in the folder containing the script, in the same folder that has the input folder, or the input folder itself.
  These three options can be adjusted by commenting out the appropriate line in the script. Please look for the section *"Set output parameters"* in the script and comment out
  the option that is not preferred. Currently, the default is such that the output is created in the input folder.


**MERGE_HDF_AGENTWISE**

- This script converts HDF5 files from ``set_*_run_*_iters.h5`` format to ``HDF5`` files per agent (**Eurostat.h5**, **Firm.h5** etc).
- A file **agentlist.txt** specifies which agent types should be considered as keys.
- For each HDF5 file (``set_*_run_*_iters.h5``) present in the input folder, the agents corresponding to an entry in the ``agentlist.txt`` file are filtered and stored inside a new agent-wise HDF5 file.
- Any help regarding the execution of the script can be obtained by using the following command in any terminal window::

        python merge_hdf_agentwise.py -h

- There is an option to specify a desired output folder for the output files, by passing an **-o** flag.
- However, by default the output is created either in the folder containing the script, in the same folder that has the input folder, or the input folder itself.
  These three options can be adjusted by commenting out the appropriate line in the script. Please look for the section *"Set output parameters"* in the script and comment out the option that is not preferred. Currently, the default is such that the output is created in the input folder.
